{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train on whole dataset and test on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from expert_tree import get_expert_tree_results, Expert_Tree\n",
    "from wrapper import best_first_search_mg\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test define feature subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats1 = ['ArmSwelling', 'FHT', 'BreastSwelling', 'Skin', 'DISCOMFORT', \n",
    "#          'TIME_LAPSE_LOG', 'Mobility', 'PAS', 'BMI', \n",
    "#          'ChestWallSwelling', 'Chemotherapy', 'Mastectomy']\n",
    "\n",
    "# feats2 = ['ArmSwelling', 'SYM_COUNT', 'FHT', 'BreastSwelling', 'Skin', 'DISCOMFORT', \n",
    "#          'TIME_LAPSE_LOG', 'Mobility', 'PAS']\n",
    "\n",
    "# feats3 = ['ArmSwelling', 'FHT', 'BreastSwelling', 'Skin', 'DISCOMFORT', \n",
    "#          'TIME_LAPSE_LOG', 'PAS', 'BMI', \n",
    "#          'SLNB_Removed_LN', 'Radiation', 'Lumpectomy', 'Chemotherapy']\n",
    "\n",
    "# feats4 = ['ArmSwelling', 'BreastSwelling', 'Skin', 'PAS', 'DISCOMFORT', 'Age', \n",
    "#          'SLNB_Removed_LN', 'BMI', 'TIME_LAPSE_LOG']\n",
    "\n",
    "# feat5 = ['ArmSwelling', 'SYM_COUNT', 'BreastSwelling', 'TIME_LAPSE_LOG', 'Age', 'Skin',\n",
    "#  'ALND_Removed_LN', 'SLNB_Removed_LN']\n",
    "\n",
    "# feat6 = ['ArmSwelling', 'SYM_COUNT', 'BreastSwelling', 'TIME_LAPSE_LOG', 'FHT', 'Age', 'Skin',\n",
    "#         'DISCOMFORT', 'Lumpectomy']\n",
    "\n",
    "# feat7 = ['ArmSwelling', 'BreastSwelling', 'Skin', 'PAS', 'FHT', 'DISCOMFORT',\n",
    "#          'SYM_COUNT', 'Chemotherapy', 'Age', 'TIME_LAPSE_LOG']\n",
    "\n",
    "# feat8 = ['ArmSwelling', 'BreastSwelling', 'Skin', 'PAS', 'FHT', 'DISCOMFORT',\n",
    "#  'SYM_COUNT', 'ALND_Removed_LN', 'Lumpectomy', 'TIME_LAPSE_LOG']\n",
    "\n",
    "# feat9 = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'Skin', 'FHT', 'SYM_COUNT',\n",
    "#  'ChestWallSwelling', 'Radiation', 'Age', 'TIME_LAPSE_LOG']\n",
    "\n",
    "feat_gbt = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'Skin', 'FHT', 'SYM_COUNT', 'Age', 'TIME_LAPSE_LOG']\n",
    "feat_gbt_without_log = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'Skin', 'FHT', 'SYM_COUNT', 'Age', 'TIME_LAPSE']\n",
    "\n",
    "\n",
    "feat_gbt_backward = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'Skin', 'SYM_COUNT',\n",
    "                     'Chemotherapy', 'Radiation', 'Age', 'Lumpectomy', 'TIME_LAPSE_LOG']\n",
    "\n",
    "# cart_feat1 = ['ArmSwelling', 'BreastSwelling', 'Skin', 'SYM_COUNT', 'Chemotherapy', 'Hormonal']\n",
    "\n",
    "# cart_feat2 = ['SYM_COUNT', 'ArmSwelling', 'BreastSwelling', 'TIME_LAPSE_LOG', 'Skin', 'Age']\n",
    "\n",
    "# cart_feat3 = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'DISCOMFORT', 'SYM_COUNT','Radiation', 'SLNB_Removed_LN', 'Lumpectomy', 'Hormonal', 'TIME_LAPSE_LOG']\n",
    "\n",
    "# cart_feat4 = ['ArmSwelling', 'BreastSwelling', 'DISCOMFORT', 'SYM_COUNT', 'Radiation'\n",
    "#               ,'SLNB_Removed_LN', 'Mastectomy', 'Lumpectomy', 'Hormonal', 'TIME_LAPSE_LOG']\n",
    "\n",
    "feat_cart = ['SYM_COUNT', 'ArmSwelling', 'BreastSwelling', 'TIME_LAPSE_LOG', 'DISCOMFORT']\n",
    "\n",
    "feat_cart_backward = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'DISCOMFORT', 'SYM_COUNT',\n",
    "                      'Radiation', 'SLNB_Removed_LN', 'Mastectomy', 'Hormonal', 'TIME_LAPSE_LOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_gbt_forward_binary = ['ArmSwelling','BreastSwelling', 'PAS', 'SYM_COUNT', 'Age', 'BMI', 'TIME_LAPSE_LOG']\n",
    "feat_gbt_backward_binary = ['Mobility', 'ArmSwelling', 'BreastSwelling', 'Skin', 'PAS', 'DISCOMFORT',\n",
    " 'SYM_COUNT', 'ChestWallSwelling', 'Chemotherapy', 'Radiation', 'Age',\n",
    " 'SLNB_Removed_LN', 'Mastectomy', 'Lumpectomy', 'Hormonal', 'BMI',\n",
    " 'TIME_LAPSE_LOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15913545, 0.54254953, 0.29831502]\n"
     ]
    }
   ],
   "source": [
    "num_class = 3\n",
    "if num_class == 2:\n",
    "    w = [0.45258215, 1-0.45258215]\n",
    "else:\n",
    "    w = [0.15913545, 0.54254953, 0.29831502]\n",
    "print(w)\n",
    "\n",
    "feats = feat_gbt\n",
    "if_all_feature = False\n",
    "if if_all_feature:\n",
    "    feats = data_train.columns.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator_type: gbt\n"
     ]
    }
   ],
   "source": [
    "estimator_types = ['gbt', 'cart']\n",
    "estimator_type = estimator_types[0]\n",
    "print('estimator_type:', estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('./data/result_data/split_train_Oct21_stratified.csv')\n",
    "#data_test = pd.read_csv('./data/result_data/split_test_Oct21_stratified.csv')\n",
    "data_test = pd.read_csv('./data/web_data_ML_correct.csv')\n",
    "overlap = set(data_train['Username'].values) & set(data_test['Username'].values)\n",
    "print(overlap)\n",
    "assert len(overlap) == 0, \"there is overlap between training and testing!!!\"\n",
    "data_train = data_train.drop(columns=['Unnamed: 0', 'Username'])\n",
    "#data_test = data_test.drop(columns=['Unnamed: 0', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: ['Mobility' 'ArmSwelling' 'BreastSwelling' 'Skin' 'FHT' 'SYM_COUNT' 'Age'\n",
      " 'TIME_LAPSE_LOG']\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = data_train[feats], data_train.iloc[:,-1]\n",
    "print('column:', X_train.columns.values)\n",
    "X_train, Y_train = X_train.values, Y_train.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre process web data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop data within a 6 months\n",
    "data_test = data_test[data_test.TIME_LAPSE >=0.5]\n",
    "data_test= data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_column = np.array(data_test['Age'])\n",
    "age_column_temp = np.array(age_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1,  9,  8,  6,  1, 12,  5,  1, 11,  1,  8,  8,  8,  7,  5, 11,\n",
       "        8,  8,  8,  7,  1,  8,  6,  7,  7,  9,  7,  1,  6, 11,  8,  1,  1,\n",
       "        5,  9,  7,  6,  7,  9,  9,  1,  9,  6,  1,  9,  7,  8,  8,  7,  6,\n",
       "        8,  8,  5, 12,  6,  7,  4,  4,  8,  1,  8,  8,  4,  9,  7,  8,  6,\n",
       "        1,  7,  6,  5,  7,  9,  7,  6,  4,  9,  7,  7,  5,  8,  1,  5,  6,\n",
       "        5,  5,  8,  1,  6,  6,  1,  6,  8,  5,  8,  8,  5,  1,  7,  5,  8,\n",
       "        9,  8,  8,  8,  1,  7,  7,  7,  6,  9,  6,  7,  8,  5,  6,  5,  8,\n",
       "        7,  9,  5,  9,  4,  8,  1,  8,  7,  1,  6,  6,  9,  9,  7,  8,  7,\n",
       "        8,  1,  7,  9,  6,  7,  7,  6,  5,  9,  6,  7,  6,  7,  6,  9,  8,\n",
       "        5,  1,  6,  9,  8,  7,  6,  1,  7,  8,  7,  8,  7,  7,  6,  8,  7,\n",
       "        6,  9,  7,  6,  8,  7,  7,  6,  4,  6,  8,  8,  7,  7,  9,  7,  5,\n",
       "        4,  7,  7,  6,  8,  7,  8,  6,  6,  6,  6,  7,  8,  9,  7,  6,  6,\n",
       "        7,  9,  8,  9,  6,  7,  7,  7,  1,  7,  7,  6,  8,  7,  8,  8,  5,\n",
       "        8,  7,  7,  6,  8,  6,  9,  6,  8,  6,  9,  1,  8,  1,  5,  7,  6,\n",
       "        9,  1,  8,  8,  6,  9,  8,  5,  6,  6,  7,  8,  1,  6,  6,  1,  9,\n",
       "        7,  6,  6,  7,  9,  6,  7,  8,  6,  7,  8,  6,  4,  8,  6,  9,  7,\n",
       "        6,  7,  7,  8, 11,  7,  9,  7,  1,  9,  1,  9,  7,  7,  3, 11,  7,\n",
       "        7, 12,  7,  5,  9,  1,  7,  6,  8,  8,  9,  9,  8,  8,  9,  9,  8],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_column_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert age categories into age in years\n",
    "age_column[age_column==0] = 23\n",
    "age_column[age_column==1] = 27\n",
    "age_column[age_column==2] = 32\n",
    "age_column[age_column==3] = 37\n",
    "age_column[age_column==4] = 42\n",
    "age_column[age_column==5] = 47\n",
    "age_column[age_column==6] = 52\n",
    "age_column[age_column==7] = 57\n",
    "age_column[age_column==8] = 62\n",
    "age_column[age_column==9] = 67\n",
    "age_column[age_column==10] = 72\n",
    "age_column[age_column==11] = 77\n",
    "age_column[age_column==12] = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Age']=age_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = data_test[feat_gbt_without_log], data_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test['TIME_LAPSE_LOG'] = np.log(X_test['TIME_LAPSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns=['TIME_LAPSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, Y_train = X_train.values, Y_train.values\n",
    "X_test, Y_test = X_test.values, Y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_class==2:\n",
    "    Y_train[Y_train==2] = 1\n",
    "    Y_test[Y_test==2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int64), array([485, 142, 259], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=70,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting tree\n",
    "if estimator_type == 'gbt':\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    params = {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 70}\n",
    "    estimator = GradientBoostingClassifier(**params)\n",
    "else:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    params = {'max_leaf_nodes': 13, 'criterion':'gini'}\n",
    "    estimator = DecisionTreeClassifier(**params)\n",
    "print(estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([137, 169], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cross-Validation </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 320\n",
    "shuffle= True\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_validate\n",
    "\n",
    "def cross_validate_custom(X, y, num_repeated, estimator):\n",
    "    n_splits = 8\n",
    "    if num_repeated > 1:\n",
    "        print(\"num_repeated is not 1\")\n",
    "        skf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=num_repeated, random_state=random_state)\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "        #     scores = cross_validate(estimator, X, y, scoring='accuracy', n_jobs=-1, cv=skf, verbose=0, \n",
    "        #                             return_estimator=True, return_train_score=True)\n",
    "    test_scores = []\n",
    "    CM = np.zeros((num_class,num_class))\n",
    "    sensitivities = []\n",
    "    sepcificities = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        estimator.fit(X_train, y_train, sample_weight=[w[i] for i in y_train])\n",
    "        score = estimator.score(X_test, y_test, sample_weight=[w[i] for i in y_test])\n",
    "        test_scores.append(score)\n",
    "        cm = confusion_matrix(y_test, estimator.predict(X_test))\n",
    "        CM += cm\n",
    "        if num_class == 2:\n",
    "            tn, fp, fn, tp = cm.ravel() \n",
    "            TPR = tp/ (tp+fn)\n",
    "            FPR = fp/(fp+tn)\n",
    "            sensitivities.append(TPR)\n",
    "            sepcificities.append(1 - FPR)\n",
    "    # return np.mean(scores['test_score']), np.mean(scores['train_score'])\n",
    "    # print(test_scores)\n",
    "    return test_scores, sensitivities, sepcificities, CM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_repeated is not 1\n",
      "Cross-Validation\n",
      "accu\n",
      "mean: 0.917498184779052\n",
      "std: 0.0316359284423817\n",
      "sensitivity\n",
      "mean: nan\n",
      "std: nan\n",
      "sepcificity\n",
      "mean: nan\n",
      "std: nan\n",
      "CM:\n",
      "[[2320.   94.   11.]\n",
      " [  26.  656.   28.]\n",
      " [   8.  158. 1129.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "c:\\users\\simay\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "test_scores, sensitivities, sepcificities, CM  = cross_validate_custom(X_train, Y_train, 5, estimator)\n",
    "print('Cross-Validation')\n",
    "print('accu')\n",
    "print('mean:', np.mean(test_scores))\n",
    "print('std:', np.std(test_scores))\n",
    "print('sensitivity')\n",
    "print('mean:', np.mean(sensitivities))\n",
    "print('std:', np.std(sensitivities))\n",
    "print('sepcificity')\n",
    "print('mean:', np.mean(sepcificities))\n",
    "print('std:', np.std(sepcificities))\n",
    "print('CM:')\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([137, 169], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, counts = np.unique(Y_test, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9a589b7a6644>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcounts\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (3,) "
     ]
    }
   ],
   "source": [
    "counts * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test using feature subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (886, 8)\n",
      "Y train: 886\n",
      "X test: (306, 8)\n",
      "Y test: 306\n"
     ]
    }
   ],
   "source": [
    "print(f'X train: {X_train.shape}')\n",
    "print(f'Y train: {len(Y_train)}')\n",
    "print(f'X test: {X_test.shape}')\n",
    "print(f'Y test: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accu:\n",
      "0.9538384300515261\n",
      "learnt importance:\n",
      "ArmSwelling\n",
      "0.445784\n",
      "SYM_COUNT\n",
      "0.423758\n",
      "BreastSwelling\n",
      "0.082886\n",
      "TIME_LAPSE_LOG\n",
      "0.036973\n",
      "Age\n",
      "0.006641\n",
      "FHT\n",
      "0.002084\n",
      "Skin\n",
      "0.001340\n",
      "Mobility\n",
      "0.000534\n"
     ]
    }
   ],
   "source": [
    "estimator= estimator.fit(X_train, Y_train, sample_weight=[w[i] for i in Y_train])\n",
    "train_accu = estimator.score(X_train, Y_train, sample_weight=[w[i] for i in Y_train])\n",
    "print('train_accu:')\n",
    "print(train_accu)\n",
    "feature_weight_pair = sorted(zip(feats, estimator.feature_importances_), key=lambda pair : pair[1], reverse=True)\n",
    "print('learnt importance:')\n",
    "for pair in feature_weight_pair:\n",
    "    print(f\"{pair[0]}\")\n",
    "    print(f\"{pair[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''accu = estimator.score(X_test, Y_test)\n",
    "print(f'accuracy: {accu}')\n",
    "CM = confusion_matrix(Y_test, estimator.predict(X_test))\n",
    "print('confusion matrix:')\n",
    "print(CM)\n",
    "if num_class == 2:\n",
    "    tn, fp, fn, tp = CM.ravel() \n",
    "    TPR = tp/ (tp+fn)\n",
    "    FPR = fp/(fp+tn)\n",
    "    print('sensitivity', TPR)\n",
    "    print('sepcifivity', 1 - FPR)\n",
    "    \n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15913545, 0.54254953, 0.29831502]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TEST ON WEB DATA </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_probs = estimator.predict_proba(X_test)\n",
    "Y_test_2_clinical_label = np.copy(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_test_2_clinical_label.shape)\n",
    "np.unique(Y_test_2_clinical_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 0.490\n",
    "label_t1 = ((Y_test_probs[:,1]+Y_test_probs[:,2])> t1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(Y_test_2_clinical_label, label_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 49,  88],\n",
       "       [  5, 164]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel() \n",
    "TPR = tp/ (tp+fn)\n",
    "FPR = fp/(fp+tn)\n",
    "accu = (tp + tn) / (tn + fp + fn + tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704142011834319 0.6423357664233577 0.696078431372549\n"
     ]
    }
   ],
   "source": [
    "print(TPR, FPR, accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I DID NOT RUN AFTER THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Calculate T1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_eval_fold(t ,y_ts, yprob, get_t1=True):\n",
    "    '''\n",
    "    assumes y_ts has 3 class classification\n",
    "    '''\n",
    "    #get probabilities\n",
    "    if get_t1:\n",
    "        print('T1')\n",
    "        ypred_current = ((yprob[:,1]+yprob[:,2])>t).astype(int)\n",
    "    else:\n",
    "        print('T2')\n",
    "        ypred_current = ((yprob[:,2] / (yprob[:,1] + yprob[:,2])) > t).astype(int) + 1\n",
    "        \n",
    "        \n",
    "    #print('y_ts_3class', y_ts)\n",
    "    #print('y_ts_2class', y_ts)\n",
    "    \n",
    "    # print('ypred',ypred_current )\n",
    "    print(confusion_matrix(y_ts, ypred_current))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_ts, ypred_current).ravel()\n",
    "    TPR = tp/ (tp+fn)\n",
    "    FPR = fp/(fp+tn)\n",
    "    \n",
    "    accu = (tp + tn) / (tn + fp + fn + tp)\n",
    "   \n",
    "    #returns senstivity and specifity\n",
    "    return TPR , 1- FPR, accu, tn, fp, fn, tp\n",
    "\n",
    "def thresholding_with_folds(Y_true, Y_prob, get_t1=True):\n",
    "    T_range = 1.005\n",
    "    t_values = list(np.arange(0.0,T_range,0.005))\n",
    "    t_values = [round(elem,3) for elem in t_values]\n",
    "    averages = []\n",
    "    for t in t_values:\n",
    "        sens_list =[]\n",
    "        spec_list =[]\n",
    "        accu_list = []\n",
    "        kf = RepeatedStratifiedKFold(n_splits=8, n_repeats=5,random_state=1)\n",
    "        # kf = KFold(n_splits=8 ,shuffle= False, random_state= True )\n",
    "        for _, test_index in kf.split(Y_prob, Y_true): #for each fold\n",
    "            # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            sens, spec, accu, _, _, _, _ = t_eval_fold(t, Y_true[test_index], Y_prob[test_index], get_t1)\n",
    "            sens_list.append(sens)\n",
    "            spec_list.append(spec)\n",
    "            accu_list.append(accu)\n",
    "        sens_avg = np.mean(sens_list)\n",
    "        sens_std= np.std(sens_list)\n",
    "        spec_avg = np.mean(spec_list)\n",
    "        spec_std =np.std(spec_list)\n",
    "        accu_avg = np.mean(accu_list)\n",
    "        accu_std = np.std(accu_list)\n",
    "        averages.append([t, sens_avg , sens_std, spec_avg, spec_std, accu_avg, accu_std])\n",
    "    return averages\n",
    "\n",
    "\n",
    "def draw_roc_curve(result_matrix, title):\n",
    "    fpr_list= []\n",
    "    tpr_list= []\n",
    "    for tup in result_matrix:\n",
    "        t = tup[0]\n",
    "        senstivity , specifity, accu = tup[1] , tup[3], tup[5]\n",
    "        tpr_list.append(senstivity)\n",
    "        fpr_list.append(1-specifity)\n",
    "        print(t ,'\\t' ,senstivity, '\\t'  ,1-specifity, '\\t', accu)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(fpr_list, tpr_list)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.show()\n",
    "    \n",
    "def test_t(t, test_2_class_labels, test_probs, title, get_t1=True):\n",
    "    result = thresholding_with_folds(test_2_class_labels, test_probs, get_t1)\n",
    "    draw_roc_curve(result, title)\n",
    "    TPR , TNR, accu, tn, fp, fn, tp = t_eval_fold(t, test_2_class_labels, test_probs, get_t1)\n",
    "    print('TPR: ', TPR)\n",
    "    print('TNR: ', TNR)\n",
    "    print('accu: ', accu)\n",
    "    print('CM')\n",
    "    print(np.array([[tn, fp],[fn, tp]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_prob = estimator.predict_proba(X_train)\n",
    "Y_train_2_class = np.copy(Y_train)\n",
    "Y_train_2_class[Y_train_2_class==2] = 1\n",
    "print(Y_train_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = list(zip(Y_train_prob[:,0], Y_train))\n",
    "#A = [x for x in A if x[1] in [1,2]]\n",
    "#print('max p1 for label 1 or 2 samples')\n",
    "#np.max(np.array(A)[:,0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = 0.49\n",
    "#ypred_current = ((Y_train_prob[:,1]+Y_train_prob[:,2])>t).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(Y_train_2_class, ypred_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = thresholding_with_folds(Y_train_2_class, Y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc_curve(result, 'ROC Curve of t1 for Decision Tree on Training Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test t \n",
    "Y_test_probs = estimator.predict_proba(X_test)\n",
    "Y_test_2_class_label = np.copy(Y_test)\n",
    "Y_test_2_class_label[Y_test_2_class_label==2] = 1\n",
    "print(Y_test_2_class_label.shape)\n",
    "np.unique(Y_test_2_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.49\n",
    "test_t(t, Y_test_2_class_label, Y_test_probs, 'ROC Curve of t1 for Decision Tree on Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_2_class = np.copy(Y_train)\n",
    "Y_train_2_class = Y_train_2_class[~(Y_train==0)]\n",
    "Y_train_2_prob = Y_train_prob[~(Y_train==0)]\n",
    "print(Y_train_2_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = thresholding_with_folds(Y_train_2_class, Y_train_2_prob, get_t1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc_curve(result, 'ROC Curve of t2 for Decision Tree on Training Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_2_class_label = np.copy(Y_test)\n",
    "Y_test_2_class_label[Y_test_2_class_label==2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 0.490\n",
    "label_t1 = ((Y_test_probs[:,1]+Y_test_probs[:,2])> t1).astype(int)\n",
    "#label_t1 = ((Y_test_probs[:,0]/(Y_test_probs[:,1]+Y_test_probs[:,2] + 0.001))<t1).astype(int)\n",
    "confusion_matrix(Y_test_2_class_label, label_t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_probs_pass_t1 = Y_test_probs[(label_t1 == 1) & ~(Y_test == 0)]\n",
    "Y_test_pass_t1 = Y_test[(label_t1 == 1) & ~(Y_test == 0)]\n",
    "print(Y_test_pass_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = 0.295\n",
    "#ypred_t2 = ((Y_test_probs_pass_t1[:,1]/(Y_test_probs_pass_t1[:,2] + 0.001)<t2) + 1).astype(int)\n",
    "test_t(t2, Y_test_pass_t1, Y_test_probs_pass_t1, 'ROC Curve of t2 for Decision Tree on Test Set', get_t1=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test using all feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.values\n",
    "X_test = data_test.values\n",
    "print(f'X train: {X_train.shape}')\n",
    "print(f'Y train: {len(Y_train)}')\n",
    "print(f'X test: {X_test.shape}')\n",
    "print(f'Y test: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 70}\n",
    "gbt = GradientBoostingClassifier(**params)\n",
    "gbt= gbt.fit(X_train, Y_train)\n",
    "feature_weight_pair = sorted(zip(data.columns.values, gbt.feature_importances_), key=lambda pair : pair[1], reverse=True)\n",
    "print('learnt importance:')\n",
    "feature_weight_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = gbt.score(X_test, Y_test, sample_weight=[w[i] for i in Y_test])\n",
    "print(f'accuracy: {accu}')\n",
    "CM = confusion_matrix(Y_test, gbt.predict(X_test))\n",
    "print('confusion matrix:')\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are sample overlap between the train and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = pd.read_csv(test_set_dir)\n",
    "dataTrain = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.merge(dataTest, dataTrain, how='inner', on=['Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(dataTest['Username'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(dataTrain['Username'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{label:count for label, count in zip(*np.unique(Y_test, return_counts=True))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{label:count for label, count in zip(*np.unique(Y_train, return_counts=True))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([583, 171, 311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = a / np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w[0] / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w / np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = [(\"Arm Swelling\", 0.456441),\n",
    "(\"Symptom Count\", 0.421406),\n",
    "(\"BreastSwelling\", 0.073692),\n",
    "(\"TIME LAPSE\", 0.037715), \n",
    "(\"Age\", 0.006301),\n",
    "(\"FHT\", 0.002236),\n",
    "(\"Fibrosis\", 0.001830),\n",
    "(\"Mobility\", 0.000378)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names, feat_scores = list(zip(*paris[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "ax.barh(feat_names, feat_scores, align='center')\n",
    "ax.set_xlabel('importance score')\n",
    "ax.set_title('importance scores leant by gradient boosting trees')\n",
    "ax.set_xlim([0, 0.5])\n",
    "for i, v in enumerate(feat_scores):\n",
    "    ax.text(v, i, str(v), color='blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
